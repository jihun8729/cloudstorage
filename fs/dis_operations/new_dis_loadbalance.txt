package dis_operations

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"math"
	"os"
	"path/filepath"
	"sort"
	"strings"
	"sync"

	"github.com/rclone/rclone/cmd"
	"github.com/rclone/rclone/fs"
	"github.com/rclone/rclone/fs/config"
	"github.com/spf13/cobra"
)

var lb_file_name = "loadbalancer.json"

type LoadBalancerType string

const (
	RoundRobin     LoadBalancerType = "RoundRobin"
	DownloadOptima LoadBalancerType = "DownloadOptima"
	UploadOptima   LoadBalancerType = "UploadOptima"
	ResourceBased  LoadBalancerType = "ResourceBased"
	// ▼ 새로 추가: 리모트별 동시 작업 개수를 하드코딩으로 제한
	StaticQuota LoadBalancerType = "StaticQuota"
	None        LoadBalancerType = "None" // Invalid value
)

// Validate the input for load balancer
func (lb LoadBalancerType) IsValid() bool {
	switch lb {
	case RoundRobin, DownloadOptima, UploadOptima, ResourceBased, StaticQuota:
		return true
	default:
		return false
	}
}

func LoadBalancer_RoundRobin() (Remote, error) {
	jsonFilePath := getLoadBalancerJsonFilePath()
	existingLBInfo, err := readJSON(jsonFilePath)
	if err != nil {
		return Remote{}, err
	}

	remotes := config.GetRemotes()
	if len(remotes) == 0 {
		return Remote{}, fmt.Errorf("no available remotes")
	}

	// Select a remote using Round Robin
	selectedRemote := remotes[existingLBInfo.RoundRobinCounter%len(remotes)]
	selectedRemoteObj := Remote{selectedRemote.Name, selectedRemote.Type}

	// Increment counters
	IncrementRoundRobinCounter()

	return selectedRemoteObj, nil
}

func LoadBalancer_DownloadOptima() (Remote, error) {
	remote, err := getRemoteOfHighestDownThroughput()
	fmt.Println("Download Optima: ", remote)

	if err != nil {
		return Remote{}, err
	}
	return remote, nil
}

func LoadBalancer_UploadOptima() (Remote, error) {
	remote, err := getRemoteOfHighestUpThroughput()
	fmt.Println("Upload Optima: ", remote)
	if err != nil {
		return Remote{}, err
	}
	return remote, nil
}

var bestRemote_save = Remote{"", ""}

func LoadBalancer_ResourceBased() (Remote, error) {
	if bestRemote_save.Name != "" && bestRemote_save.Type != "" {
		return bestRemote_save, nil
	}

	remotes := config.GetRemotes()
	var errs []error
	var wg sync.WaitGroup
	var mu sync.Mutex // To protect shared variables

	var bestRemote Remote
	var maxFreeStorage int64

	for _, remote := range remotes {
		wg.Add(1)
		go func(remote config.Remote) {
			defer wg.Done()

			val, err := RemoteCallAbout([]string{remote.Name + ":"})
			if err != nil {
				mu.Lock()
				errs = append(errs, fmt.Errorf("error in remoteCallAbout for remote %s: %w", remote.Name, err))
				mu.Unlock()
				return
			}

			mu.Lock()
			if val > maxFreeStorage {
				maxFreeStorage = val
				bestRemote = Remote{remote.Name, remote.Type}
			}
			mu.Unlock()

		}(remote)
	}

	wg.Wait()

	// If there were errors and no valid remote found, return an error
	if len(errs) == len(remotes) {
		return Remote{}, fmt.Errorf("all remotes failed: %v", errs)
	}

	bestRemote_save = bestRemote
	return bestRemote, nil
}

func IncrementRoundRobinCounter() error {
	jsonFilePath := getLoadBalancerJsonFilePath()
	existingLBInfo, err := readJSON(jsonFilePath)
	if err != nil {
		return err
	}

	existingLBInfo.RoundRobinCounter = (existingLBInfo.RoundRobinCounter + 1)

	return writeJSON(jsonFilePath, existingLBInfo)
}

func UpdateRemoteInfo(remote Remote, updateFunc func(*RemoteInfo)) error {
	jsonFilePath := getLoadBalancerJsonFilePath()
	lbInfo, err := getLoadBalancerInfo(jsonFilePath)
	if err != nil {
		return err
	}

	// Get or initialize RemoteInfo (use pointer to it)
	remoteInfo := getRemoteInfo(remote, lbInfo)

	// Apply the provided update function
	updateFunc(&remoteInfo)

	// Since the map stores struct values, we must explicitly update it
	lbInfo.RemoteInfos[remote.String()] = remoteInfo

	// Write updated info back to JSON
	err = writeJSON(jsonFilePath, lbInfo)
	if err != nil {
		return fmt.Errorf("failed to write JSON: %w", err)
	}

	return nil
}

func getLoadBalancerJsonFilePath() string {
	path := GetRcloneDirPath()

	// Construct the file path
	filePath := filepath.Join(path, "data", lb_file_name)

	// Check if the file exists
	if _, err := os.Stat(filePath); os.IsNotExist(err) {
		// Create the directories if they don't exist
		err := os.MkdirAll(filepath.Dir(filePath), 0755)
		if err != nil {
			fmt.Println("Error creating directories:", err)
			return ""
		}

		// Create the JSON file
		file, err := os.Create(filePath)
		if err != nil {
			fmt.Println("Error creating file:", err)
			return ""
		}
		defer file.Close()

		// Initialize LoadBalancerInfo with default values
		lbInfo := LoadBalancerInfo{
			RoundRobinCounter: 0,
			RemoteInfos:       make(map[string]RemoteInfo),
		}

		// Marshal the LoadBalancerInfo struct to JSON format
		data, err := json.MarshalIndent(lbInfo, "", "  ")
		if err != nil {
			fmt.Println("Error marshaling data:", err)
			return ""
		}

		// Write the initialized data to the file
		_, err = file.Write(data)
		if err != nil {
			fmt.Println("Error writing to file:", err)
			return ""
		}
	}

	return filePath
}

func readJSON(filename string) (*LoadBalancerInfo, error) {
	// Open the file
	file, err := os.Open(filename)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	// Read the file contents
	var lbInfo LoadBalancerInfo
	decoder := json.NewDecoder(file)
	err = decoder.Decode(&lbInfo)
	if err != nil {
		return nil, err
	}

	return &lbInfo, nil
}

func writeJSON(filename string, lbInfo *LoadBalancerInfo) error {
	data, err := json.MarshalIndent(lbInfo, "", "  ")
	if err != nil {
		return err
	}

	err = os.WriteFile(filename, data, 0644)
	if err != nil {
		return err
	}

	return nil
}

func getLoadBalancerInfo(jsonFilePath string) (*LoadBalancerInfo, error) {
	existingLBInfo, err := readJSON(jsonFilePath)
	if err != nil {
		return nil, err
	}

	return existingLBInfo, nil
}

func getRemoteInfo(remote Remote, loadBalancerInfo *LoadBalancerInfo) RemoteInfo {
	if loadBalancerInfo.RemoteInfos == nil {
		loadBalancerInfo.RemoteInfos = make(map[string]RemoteInfo)
	}

	remoteKey := remote.String()

	// Retrieve the RemoteInfoData for the given remote
	remoteInfo, exists := loadBalancerInfo.RemoteInfos[remoteKey]

	// If the data does not exist, create a new one
	if !exists {
		remoteInfo = RemoteInfo{
			UpThroughputHistory: []float64{},
			AvgUpThroughput:     0,
		}
	}

	// Since the map stores struct values, we must explicitly update it
	loadBalancerInfo.RemoteInfos[remoteKey] = remoteInfo

	// Return a pointer to the map entry (modifications will persist)
	return loadBalancerInfo.RemoteInfos[remoteKey]
}

func getRemoteOfHighestUpThroughput() (Remote, error) {
	return getRemoteOfHighestThroughput(func(info RemoteInfo) float64 {
		return info.AvgUpThroughput
	})
}

func getRemoteOfHighestDownThroughput() (Remote, error) {
	return getRemoteOfHighestThroughput(func(info RemoteInfo) float64 {
		return info.AvgDownThroughput
	})
}

func getRemoteOfHighestThroughput(selector func(RemoteInfo) float64) (Remote, error) {
	jsonFilePath := getLoadBalancerJsonFilePath()
	existingLBInfo, err := readJSON(jsonFilePath)
	if err != nil {
		return LoadBalancer_RoundRobin()
	}

	var maxKey string
	var maxValue float64
	firstIteration := true

	// Find the remote with the highest average throughput
	for key, value := range existingLBInfo.RemoteInfos {
		currentVal := selector(value)
		if currentVal == 0 {
			continue
		}
		if firstIteration || currentVal > maxValue {
			maxValue = currentVal
			maxKey = key
			firstIteration = false
		}
	}

	// Handle empty counter case
	if maxKey == "" {
		return LoadBalancer_RoundRobin()
	}

	// Split the key back into Name and Type
	parts := strings.Split(maxKey, "|")
	if len(parts) != 2 {
		return LoadBalancer_RoundRobin()
	}

	return Remote{
		Name: parts[0],
		Type: parts[1],
	}, nil
}

var aboutCommandDefinitionForRemoteCall = &cobra.Command{
	Use: "about remote:",
	Annotations: map[string]string{
		"versionIntroduced": "v1.41",
	},
	Run: func(command *cobra.Command, args []string) {
		cmd.CheckArgs(1, 1, command, args)
		f := cmd.NewFsSrc(args)

		cmd.RunWithSustainOS(false, false, command, func() error {
			freeStorage, err := getFreeStorage(f)
			if err != nil {
				return err
			}

			// Print free storage
			fmt.Printf("Remote %s Free Storage: %v\n", args[0], freeStorage)

			// Store free storage in the command context for later retrieval
			command.SetContext(context.WithValue(command.Context(), "freeStorage", freeStorage))

			return nil
		}, true)
	},
}

// Function to call the new command definition and return free storage
func RemoteCallAbout(args []string) (int64, error) {
	fmt.Printf("Calling remoteCallAbout with args: %v\n", args)

	// Create a new command instance
	aboutCommand := *aboutCommandDefinitionForRemoteCall
	aboutCommand.SetArgs(args)

	// Execute the command
	err := aboutCommand.Execute()
	if err != nil {
		return 0, fmt.Errorf("error executing aboutCommand: %w", err)
	}

	// Retrieve free storage from the command context
	freeStorage, ok := aboutCommand.Context().Value("freeStorage").(int64)
	if !ok {
		return 0, errors.New("failed to retrieve free storage")
	}

	return freeStorage, nil
}

// Helper function to get free storage
func getFreeStorage(f fs.Fs) (int64, error) {
	doAbout := f.Features().About
	if doAbout == nil {
		return 0, fmt.Errorf("%v doesn't support about", f)
	}

	u, err := doAbout(context.Background())
	if err != nil {
		return 0, fmt.Errorf("about call failed: %w", err)
	}
	if u == nil {
		return 0, errors.New("nil usage returned")
	}

	// Return free storage
	return *u.Free, nil
}

func GetLBFileName() string {
	return lb_file_name
}

var (
	shardPlan   map[string]int
	shardRemain map[string]int
	shardMu     sync.Mutex
	shardRR     int
)

func weightedBaseDistribution(up map[string]float64, dn map[string]float64, dataShards int) map[string]int {
	weights := make(map[string]float64)
	for k := range up {
		invSum := (1.0 / up[k]) + (1.0 / dn[k])
		weights[k] = 1.0 / invSum
	}

	total := 0.0
	for _, v := range weights {
		total += v
	}

	dist := make(map[string]int)
	for k, v := range weights {
		dist[k] = int(math.Round((v / total) * float64(dataShards)))
	}

	// 합계 보정
	diff := dataShards - sumInt(dist)
	if diff != 0 {
		fastest := maxKey(up)
		dist[fastest] += diff
	}
	return dist
}
func expandWithParity(baseDist map[string]int, up map[string]float64, parityShards int, shardSizeMB float64, baseUp float64) map[string]int {
	dist := copyMap(baseDist)
	if parityShards <= 0 {
		return dist
	}

	for i := 0; i < parityShards; i++ {
		type candidate struct {
			key     string
			newUp   float64
			upDelta float64
		}
		var valid []candidate
		var fallback []candidate

		for k := range dist {
			trial := copyMap(dist)
			trial[k]++
			newUp := uploadMakespan(trial, up, shardSizeMB)
			delta := newUp - baseUp
			if newUp <= baseUp+1e-9 {
				valid = append(valid, candidate{k, newUp, delta})
			} else {
				fallback = append(fallback, candidate{k, newUp, delta})
			}
		}

		if len(valid) > 0 {
			sort.Slice(valid, func(i, j int) bool { return valid[i].newUp < valid[j].newUp })
			dist[valid[0].key]++
		} else {
			sort.Slice(fallback, func(i, j int) bool { return fallback[i].upDelta < fallback[j].upDelta })
			dist[fallback[0].key]++
			baseUp = uploadMakespan(dist, up, shardSizeMB)
		}
	}
	return dist
}
func uploadMakespan(dist map[string]int, up map[string]float64, shardSizeMB float64) float64 {
	maxTime := 0.0
	for k, v := range dist {
		t := (shardSizeMB * float64(v) * 8.0) / up[k]
		if t > maxTime {
			maxTime = t
		}
	}
	return maxTime
}

func copyMap(m map[string]int) map[string]int {
	cp := make(map[string]int)
	for k, v := range m {
		cp[k] = v
	}
	return cp
}

func sumInt(m map[string]int) int {
	s := 0
	for _, v := range m {
		s += v
	}
	return s
}

func maxKey(m map[string]float64) string {
	maxK := ""
	maxV := -1.0
	for k, v := range m {
		if v > maxV {
			maxV = v
			maxK = k
		}
	}
	return maxK
}

func ComputeShardDistribution(dataShards int, parityShards int) error {
	// lbInfo 불러오기
	jsonFilePath := getLoadBalancerJsonFilePath()
	lbInfo, err := readJSON(jsonFilePath)
	if err != nil {
		return err
	}

	// 업로드/다운로드 평균속도 맵 생성
	up := make(map[string]float64)
	dn := make(map[string]float64)
	for k, info := range lbInfo.RemoteInfos {
		up[k] = info.AvgUpThroughput
		dn[k] = info.AvgDownThroughput // ❗ lbInfo.RemoteInfos에 추가 필요
	}

	// Base 분배 (dataShards만 사용)
	baseDist := weightedBaseDistribution(up, dn, dataShards)
	fmt.Println("Base distribution:", baseDist)

	// Base makespan 계산
	baseUp := uploadMakespan(baseDist, up, 16.0)

	//  parityShards를 makespan 유지 조건으로 brute-force 추가
	finalDist := expandWithParity(baseDist, up, parityShards, 16.0, baseUp)

	// 결과 저장
	shardPlan = finalDist
	shardRemain = copyMap(finalDist)

	fmt.Println("Shard distribution plan (Data:", dataShards, "Parity:", parityShards, ")")
	for k, v := range shardPlan {
		fmt.Printf("  %s -> %d shards\n", k, v)
	}
	fmt.Printf("   ⏱️ Upload makespan: %.2fs\n", uploadMakespan(shardPlan, up, 16.0))

	return nil
}

func combinations2(keys []string) [][]string {
	var res [][]string
	for i := 0; i < len(keys); i++ {
		for j := i + 1; j < len(keys); j++ {
			res = append(res, []string{keys[i], keys[j]})
		}
	}
	return res
}

func isRecoverable(plan map[string]int, dataShards int, storages []string) bool {
	combos := combinations2(storages)
	for _, combo := range combos {
		total := plan[combo[0]] + plan[combo[1]]
		if total < dataShards {
			return false
		}
	}
	return true
}

func unrecoveredCombos(plan map[string]int, dataShards int, storages []string) [][]string {
	var res [][]string
	combos := combinations2(storages)
	for _, combo := range combos {
		total := plan[combo[0]] + plan[combo[1]]
		if total < dataShards {
			res = append(res, combo)
		}
	}
	return res
}

func variable_coderate_plan(fileSize int64) (int, int) {

	dataShards := int(math.Ceil(float64(fileSize) / (16 * 1024 * 1024)))

	// --- LB 정보 로드 ---
	jsonFilePath := getLoadBalancerJsonFilePath()
	lbInfo, _ := readJSON(jsonFilePath)

	up := make(map[string]float64)
	dn := make(map[string]float64)
	var storages []string
	for k, info := range lbInfo.RemoteInfos {
		storages = append(storages, k)
		up[k] = info.AvgUpThroughput
		dn[k] = info.AvgDownThroughput
	}

	// --- Base ---
	baseDist := weightedBaseDistribution(up, dn, dataShards)

	fmt.Println("Base distribution:", baseDist)

	// --- Parity 추가 ---
	parity := 0
	plan := copyMap(baseDist)

	for {
		if isRecoverable(plan, dataShards, storages) {
			break
		}

		parity++
		baseTime := uploadMakespan(plan, up, 16.0)

		combos := unrecoveredCombos(plan, dataShards, storages)

		bestDelta := math.MaxFloat64
		var bestStorage string

		for _, combo := range combos {
			s1, s2 := combo[0], combo[1]

			for _, target := range []string{s1, s2} {
				trial := copyMap(plan)
				trial[target]++

				newTime := uploadMakespan(trial, up, 16.0)
				delta := newTime - baseTime

				if delta < bestDelta {
					bestDelta = delta
					bestStorage = target
				}
			}
		}

		plan[bestStorage]++
		fmt.Printf("Parity %d added to %s (Δmakespan=%.4fs)\n", parity, bestStorage, bestDelta)
	}

	shardPlan = plan
	shardRemain = copyMap(plan)

	fmt.Printf("\nShard distribution plan (Data: %d, Parity: %d)\n", dataShards, parity)

	for k, v := range shardPlan {
		fmt.Printf("  %s -> %d shards\n", k, v)
	}

	fmt.Printf("   ⏱️ Upload makespan: %.2fs\n", uploadMakespan(shardPlan, up, 16.0))

	return dataShards, parity
}

func LoadBalancer_StaticQuota() (Remote, error) {
	shardMu.Lock()
	defer shardMu.Unlock()

	if len(shardRemain) == 0 {
		return Remote{}, fmt.Errorf("no shard plan initialized")
	}

	// 라운드로빈 돌면서 남은 shard 있는 remote 찾기
	keys := make([]string, 0, len(shardRemain))
	for k := range shardRemain {
		keys = append(keys, k)
	}

	n := len(keys)
	for i := 0; i < n; i++ {
		idx := (shardRR + i) % n
		key := keys[idx]
		if shardRemain[key] > 0 {
			shardRemain[key]--
			shardRR = (idx + 1) % n

			parts := strings.Split(key, "|")
			if len(parts) != 2 {
				return Remote{}, fmt.Errorf("invalid key format: %s", key)
			}
			return Remote{Name: parts[0], Type: parts[1]}, nil
		}
	}

	return Remote{}, fmt.Errorf("all shard quotas exhausted")
}
